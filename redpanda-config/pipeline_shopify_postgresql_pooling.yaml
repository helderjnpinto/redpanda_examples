# ============================================
# Redpanda Connect: PostgresQL â†’ ClickHouse (Deduped + Batched)
# ============================================
input:
  generate:
    interval: '10s' # Configure batch time
    mapping: 'root = {}'
  processors:
    - sql_raw:
        driver: clickhouse
        dsn: "clickhouse://${CLICKHOUSE_USER}:${CLICKHOUSE_PASSWORD}@clickhouse:9000/analytics"
        query: |
          SELECT event_time
          FROM events_raw
          ORDER BY event_time DESC
          LIMIT 1;
    - mapping: |
        root = this
    - unarchive:
        format: json_array
    - mapping: |
        root = this
    - log:
        level: INFO
        message: "Fetching rows with date >= ${! this.event_time }"
    - sql_raw:
        driver: postgres
        dsn: postgres://postgres:password@db:5432/shopify_data_pruned?sslmode=disable
        query: |
          SELECT md5(
                         concat_ws(
                                 '::',
                                 'free-soul-sistas',
                                 o.created_at::text,
                                 'order_created',
                                 CASE
                                     WHEN 'Subscription Recurring Order' = ANY (o.tags) THEN 'recurring'
                                     WHEN 'Subscription First Order' = ANY (o.tags) THEN 'first'
                                     WHEN so.subscription_id IS NULL THEN 'onetime'
                                     END,
                                 s.id::text,
                                 o.id::text
                         )
                 )                                                    AS event_id,
                 'free-soul-sistas'                                   AS tenant_id,
                 o.created_at                                         AS event_time,
                 'order_created'                                      AS event_type,
                 'active'                                             AS status_after, --TODO: 'active' para onetime ?
                 so.subscription_id                                   AS subscription_id,
                 o.customer_id                                        AS customer_id,
                 CASE
                     WHEN 'Subscription Recurring Order' = ANY (o.tags) THEN 'recurring'
                     WHEN 'Subscription First Order' = ANY (o.tags) THEN 'first'
                     WHEN subscription_id is NULL THEN 'onetime'
                     END                                              AS revenue_type,
                 coalesce((o.subtotal_price * 100)::bigint, 0)        AS price_cents,
                 coalesce((o.total_tax * 100)::bigint, 0)             AS tax_cents,
                 coalesce((s.delivery_price_amount * 100)::bigint, 0) AS shipping_cents,
                 CASE
                     WHEN subscription_id is NOT NULL THEN 30
                     ELSE 0 -- onetime
                     END                                              AS interval_days,
                 NULL                                                 AS plan_id,
                 NULL                                                 AS region,
                 o.source                                             AS channel,
                 o.currency                                           AS currency,
                 NULL                                                 AS cancellation_reason,
                 NULL                                                 AS pause_reason
          FROM orders o
                   LEFT JOIN subscription_orders so
                             ON o.id = so.order_id
                   LEFT JOIN subscriptions s
                             ON so.subscription_id = s.id
          WHERE o.state NOT IN ('cancelled', 'refunded')
          AND o.created_at > $1
          ORDER BY event_time
          LIMIT 1;
        args_mapping: |
          root = [ this.event_time ]
    # Check if sql_select returned no rows and exit if empty
    - mapping: |
        root = this
    - log:
        level: INFO
        message: "${! this.length() }}"

pipeline:
  processors:
    - unarchive:
        format: json_array
    - mapping: |
        root = this
    - dedupe:
        cache: keycache
        key: ${! this.event_id }

output:
  sql_insert:
    driver: clickhouse
    dsn: "clickhouse://${CLICKHOUSE_USER}:${CLICKHOUSE_PASSWORD}@clickhouse:9000/analytics"
    table: events_raw
    columns:
      - tenant_id
      - event_time
      - event_type
      - status_after
      - subscription_id
      - customer_id
      - revenue_type
      - price_cents
      - shipping_cents
      - tax_cents
      - interval_days
      - plan_id
      - region
      - channel
      - currency
      - cancellation_reason
      - pause_reason
    args_mapping: |
      root = [
        this.tenant_id,
        this.event_time,
        this.event_type,
        this.status_after,
        this.subscription_id,
        this.customer_id,
        this.revenue_type,
        this.price_cents,
        this.shipping_cents,
        this.tax_cents,
        this.interval_days,
        this.plan_id,
        this.region,
        this.channel,
        this.currency,
        this.cancellation_reason,
        this.pause_reason
      ]
    batching:
      count: 20000
      period: 1s

cache_resources:
  # Redis cache to track processed keys
  - label: keycache
    redis:
      url: redis://redis:6379
      default_ttl: 60s
      retries:
        initial_interval: 500ms
        max_interval: 1s
        max_elapsed_time: 5s
  # Memory cache for batch_count (batch mode)
  - label: batchcache
    memory: { }