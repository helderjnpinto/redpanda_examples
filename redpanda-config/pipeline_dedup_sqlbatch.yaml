# ============================================
# Redpanda Connect: PostgresQL â†’ ClickHouse (Deduped + Batched)
# ============================================

# TODO: Pass last_id to sql_select args_mapping

input:
  generate:
    interval: '@every 5s'
    mapping: 'root = {}'
  processors:
    - log:
        level: INFO
        message: "Teste 1"
    - sql_select:
        driver: postgres
        dsn: postgres://user:password@db:5432/redpanda_pipeline?sslmode=disable
        table: target_table
        columns: [ "*" ]
        where: id > ?
        args_mapping: '[ 0 ]'
        suffix: ORDER BY id LIMIT 5

pipeline:
  processors:
    - log:
        level: INFO
        message: "Rows=${! this }"
    - unarchive:
        format: json_array
    - dedupe:
        cache: keycache
        key: ${! this.id }
    - mapping: |
        meta last_id = this.id
        root = this
    - log:
        level: INFO
        message: "Processing ID = ${! this.id }"

output:
  sql_insert:
    driver: clickhouse
    dsn: "clickhouse://${CLICKHOUSE_USER}:${CLICKHOUSE_PASSWORD}@clickhouse:9000/analytics"
    table: events_raw
    columns:
      - id
      - name
      - email
    args_mapping: |
      root = [
        this.id,
        this.name,
        this.email
      ]
  processors:
    - log:
        level: INFO
        message: "Inserting to ClickHouse: ID=${! this.id }"

# Redis cache to track processed keys
cache_resources:
  - label: keycache
    redis:
      url: redis://redis:6379
      default_ttl: 60s
      retries:
        initial_interval: 500ms
        max_interval: 1s
        max_elapsed_time: 5s